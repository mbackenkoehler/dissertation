\chapter{Background}\label{ch:background}

\section{Continuous-time Markov Chains}
A \emph{stochastic process} is a parameterized collection of random variables $\{X_t\}_{t\in T}$ defined on some probability space $(\Omega, \mathcal{F}, P)$ and takes values in complete metric space $(\mathcal{S}, r)$.\graffito{See \citet{oksendal2013stochastic} for stoch.\ processes in general.}
In most contexts the index set $T$ models \emph{time}.
In a discrete setting $T=\mathbb{N}$, while $T=[0,\infty)$ in the continuous setting, which we consider in this thesis.
We observe the values $X(t, \omega)$ for some fixed, but unknown $\omega\in\Omega$.
The information of the process up to time $t$ is given by the $\sigma$-algebra $\mathcal{F}_t\subset\mathcal{F}$.
The increasing family of sigma algebras, i.e.\ $\mathcal{F}_s\subseteq\mathcal{F}_t$ for $s\leq t$ is called a \emph{filtration}.

More specifically, we study with models having \acf{CTMC} semantics.
A \ac{CTMC} is a stochastic processes, that takes discrete values $\mathcal{S}=\{s_0, s_1,\dots\}$ over continuous time $T=[0,\infty)$ and fulfills the \emph{Markov property}
\begin{equation}\label{eq:markov_prop}
	\begin{split}
		&\Pr\left({X_{t_2} = s_2 \mid X_{t_1} = s_1}\right) \\ = &\Pr\left({X_{t_2}=s_2 \mid X_{t_1} = s_1, X_{t_0} = s_0}\right)
	\end{split}
\end{equation}
for all time points $t_2 \geq t_1 \geq t_0$ and $s_0, s_1, s_2\in\mathcal{S}$.
Intuitively, this property expresses that the future of the process ($t=t_2$) depends only on the latest condition, i.e.\ $X_{t_1}=s_1$ and not earlier conditions ($X_{t_0}=x_0$).
If further
\begin{equation}\label{time_homo}
	\Pr\left(X_t=s_1\mid X_0 = s_0\right)
	=\Pr\left(X_{t+h}=s_1\mid X_h=s_0\right)
\end{equation}
for all $t,h\geq 0$ and $s_0, s_1\in\mathcal{S}$ the chain is \emph{time-homogenous}:
The absolute time point is irrelevant, and the dynamics do not change if we shift in time.
In this thesis we are only interested in tim-homogenous \acp{CTMC}, but most techniques 
developed should carry over.
We define \emph{transition probabilities}
\begin{equation}
	p_{ij}(h) = \Pr(X_h = s_j\mid X_0=s_i)\,.
\end{equation}
Accordingly, the \emph{transition matrix} is given by $P(h)_{ij} = p_{ij}(h)$ for all indices $i$ and $j$.
The Chapman-Kolmogorov equation
\begin{equation}\label{eq:chapman_kolm}
	P(s+t) = P(s)P(t)
\end{equation}
follows directly from the law of total probability and the Markov property \eqref{eq:markov_prop}.
\eqref{eq:chapman_kolm} directly tells us that the transition probabilities
from a semigroup.
Studying Markov processes from this direction is a popular approach \cite{ethier2009markov}.

A standard method of specifying a Markov process, and \acp{CTMC} in particular, is
is the \emph{generator}.
In general, this is an operator $A$ on some class of functions and
\begin{equation}
	\E{f(X_{t+h} - f(X_t)\mid \mathcal{F}_t}
	=
	Af(X_t)h + o(h)\,,
\end{equation}
where $\mathcal{F}_t$ is the filtration up to time $t$.
This equation can be interpreted as the requirement, that
$$f(X_t) - f(X_0) - \int_0^t Af(x_s)\,ds$$ is a martingale \cite[p.~5]{kurtz1981approximation}.
We will use this in \autoref{ch:MFPT} to derive bounds on \aclp{MFPT}.

In \acp{CTMC} the generator is defined by giving the \emph{intensities} or \emph{rates}
of transitions.
Such a rate $q_{ij} > 0$ between state $s_i$ and $s_j$ implies
\begin{equation}
	\Pr(X_{h} = s_j\mid X_0=s_i) = q_{ij}h + o(h)\,.
\end{equation}
%The $Q$-matrix characterizes the distributional change in the infinitesimal time interval:
Due to the discrete nature, the generator is a matrix, usually called the $Q$-matrix,
\begin{equation}
	Q = \lim_{h\downarrow 0}\frac{1}{h}\left(P(h) - I\right)\,.
\end{equation}
As such the change of the state probability distribution over time is fully characterized by the \emph{Kolmogorov forward equation}
\begin{equation}\label{eq:kolm_forw}
	\frac{d}{dt}P(t) = P(t)Q\,.
\end{equation}
Analogously, the \emph{Kolmogorov backward equation} is
\begin{equation}\label{eq:kolm_back}
	\frac{d}{dt}P(t) = QP(t)^{\T}\,.
\end{equation}
Distributions in the context of Markov chains are typically in row-vector form
$$
\pi(t)\coloneqq(\pi(x_1, t), \pi(x_2, t), \dots)\,,
$$
where we define
$$
\pi(x_i, t)\coloneqq \Pr(X_t=x_i), \quad\forall x_i\in\mathcal{S}, \forall{t\geq 0}\,.
$$
Often, \eqref{eq:kolm_forw} and \eqref{eq:kolm_back} are used in the context of an
distributions.
In this case it makes more sense to right-multiply $\vec{1}$ to these equations such
that
\begin{equation}\label{eq:kolm_forw_d}
	\frac{d}{dt}\pi(t) = \pi(t)Q
\end{equation}
and
\begin{equation}\label{eq:kolm_back_d}
	\frac{d}{dt}\pi(t) = Q\pi(t)^{\T}\,.
\end{equation}
Given some initial distribution
$$
\pi_0 \coloneqq \pi(0)\,,
$$
the distribution $\pi(t)$ is given by give simple \acp{IVP} of \eqref{eq:kolm_forw_d}.

\subsection{Computing Transient Distributions}
\citet{stewart1994introduction} provides a comprehensive overview of solution methods.
Here, we only provide a basic overview and intuition relevant for the rest of this thesis.
\begin{description}
	\item[Matrix exponential]
		The transition probability matrix $P(t)$ is the solution of \eqref{eq:kolm_forw}
		$$
			P(t)=\exp(Qt)\,,
			$$
		where the matrix exponential for a square matrix $M$
		$$
		\exp({M})\coloneqq\sum_{k=0}^{\infty}\frac{1}{k!}M^k\,.
		$$
		Due to the factor ${h^k}/{k!}$, the sum of the matrix exponential
		can be truncated to get an estimate
		of high quality. In practice, this method is unsuited to many problems, because
		the factor $Q^k$ becomes incurs a prohibitive cost, especially if the state space
		is large.
	\item[Numerical integration]
		The Kolmogorov equations \eqref{eq:kolm_forw}, \eqref{eq:kolm_back}
		provide us with an \ac{IVP} that can be solved
		numerically.\graffito{The matrix exponential is the analytical solution.}
		This method scales much better than the matrix exponential method,
		especially if the whole time-series is of interest. If an initial distribution
		$\pi_0$ is fixed, the \ac{ODE} simplify further, such that we only have one equation
		per state.
		The drawback to this method is the error inherent to numerical 
		integration schemes.
	\item[Uniformization]
		Uniformization is an elegant algorithm to compute transient solutions.
		Here, the \ac{CTMC} is transformed into a \ac{DTMC}.
		Using a uniformization rate $$\lambda_0\geq\max_{i}\lvert q_{ii}\rvert$$
		the transition probabilities of the \ac{DTMC} become
		$$
		P_{ij} =
		\begin{cases}
			Q_{ij} / \lambda_0\,, &\text{if } i\neq j\\
			1 - \sum_k Q_{ik} / \lambda_0\,, &\text{otherwise}
		\end{cases}\,.
		$$
		The transient distribution at $t$ can be obtained, by weighting the $k$-step
		probabilities of the \ac{DTMC} by a Poisson distribution with rate
		$\lambda_0 t$:
		$$
		\pi(t) =
		\sum_{k=0}^{\infty}\pi_0P^k\frac{(\lambda_0 t)^k}{k!} \exp{(\lambda_0 t)}\,.
		$$
		Truncation of this series clearly gives an underapproximation.
	\item[Monte Carlo simulation]
		A simple way is estimation using Monte Carlo methods. This entails stochastic
		simulation of many trajectories of the \ac{CTMC}. Generating a trajectory is
		straightforward: Given that the process is in a particular state $s_i$
		the a transition has to be sampled along with the residence time in state
		$s_i$. The naive approach is to sample an exponential random variable for
		each $q_{ij}$ and choose the one firing first.
		This algorithm can be improved by sampling a reaction directly and
		sampling the residence time separately. This algorithm will be shown later
		in the context of \acp{MPM}.\turnto{alg:ssa}
\end{description}
% \begin{itemize}
%    \item Properties (non-explosivity, ergodicity, reversibility, irreducibility etc.)
% \end{itemize}

\section{Markovian Population Models}
An \acf{MPM}
describes the stochastic interactions
among agents of $n_S$ distinct types in a well-stirred system.
The system is given by a continuous-time stochastic process $\{X_t\}_{t\geq 0}$.
It models only the number of agents according to their type.
Therefore the process takes $n_S$-dimensional vectors of natural numbers as values, i.e.\ the
state-space is $\mathcal{S}\subseteq\mathbb{N}^{n_S}$.
By only considering the number of agents, we are neglecting factors such as spatial variations
in agent density or other factors influencing interactions.
The assumption of all agents being equally distributed in space is called the \emph{well-stirredness}
assumptions.

Interactions between agents are expressed as \emph{reactions}.
These reactions have associated
gains and losses of agents, given by non-negative integer vectors   
${v}_j^{-}$ and ${v}_j^{+}$ for reaction $j$, respectively. The overall change by a reaction is given by the vector $v_j = v_j^+ - v_j^-$.
A reaction between agents of types $S_1,\dots, S_{n_S}$ is specified in the following form:
\begin{equation}\label{eq:reaction}
    \sum_{\ell=1}^{n_S} v_{j\ell}^{-} S_\ell
    \xrightarrow{\alpha_j( x)}
    \sum_{\ell=1}^{n_S} v_{j\ell}^{+} S_\ell\,.
\end{equation}
The propensity function $\alpha_j$ gives the rate of the exponentially distributed firing
time of the reaction as a function of the current system state $x\in \mathcal{S}$.
Thus, for reaction $j$ we have the intensity
\begin{equation}\label{eq:firing}
	\Pr\left(X_{t+h}=x+v_j\mid X_{t}=x\right)
	=
	\alpha_j(x) + o(h t)\,.
\end{equation}


In most physical models, \emph{mass-action} propensities are most common.
These model combinatorial nature of well-mixed molecules moving randombly through space:
In a reaction
$$ A + B \xrightarrow{c x^{(A)} x^{(B)}} C $$
two molecules hit eachother with a probability, proportional to the product of their counts
$$ c X^{(A)}_t X^{(B)}_t\,. $$
In general such rates are given by the product of the number
of reactant combinations in $x$ and a
\emph{rate constant} $c_j$, i.e.
\begin{equation}\label{eq:stoch_mass_action}
	\alpha_j({x})\coloneqq c_j\prod_{\ell=1}^{n_S}\binom{x^{(S_{\ell})}}{v_{j\ell}^{-}}\,.
\end{equation}
In this case, we give the rate constant in \eqref{eq:reaction} instead of the function $\alpha_j$.
We use the superscript notation\marginpar{This notation avoids conflicts, when we use the subscript for time or as an index.} $x^{(A)}$ to denote the index corresponding to species $A$ 
in some vector of length $n_S$.

According to \eqref{eq:firing} the stochastic
process $\{{{X}}_t\}_{t\geq 0}$ describing the evolution of the population
sizes over time $t$ is a \acf{CTMC}.
The infinitesimal  generator matrix $Q$ has the entries
\begin{equation}\label{eq:cme_generator}
    Q_{ x,  y} = \begin{cases}
        \sum_{j: x+ v_j = y}\alpha_j( x)\,,&\text{if}\; x\neq
         y,\\[1ex]
        -\sum_{j=1}^{n_R} \alpha_j( x)\,, &\text{otherwise.}
    \end{cases}
\end{equation}
Note that in addition mild regularity assumptions
are   necessary for the existence of a unique \ac{CTMC} $X$, such as non-explosiveness \cite{anderson2012continuous}.
These assumptions  are  typically
valid for realistic reaction networks.
The probability distribution over time is given by an
initial value problem.
Given an initial state $x_0$, the distribution\graffito{We assume an enumeration of all states in  $\mathcal{S}$ with a unique index for each state.}
\begin{equation}\label{eq:forw_prob}
\pi(x_i, t)=\Pr(X_t=x_i\mid X_0=x_0),\quad t\geq 0
\end{equation}
evolves according to the Kolmogorov forward equation
\begin{equation}\label{eq:forward}
\frac{d}{dt}\pi(t) = \pi(t) Q\,,
\end{equation}
where $\pi(t)$ is an arbitrary vectorization $$(\pi(x_1,t), \pi(x_2,t),\dots,\pi(x_{|\mathcal{S}|},t))$$ of the states.
\eqref{eq:forw_prob} given for a single state, in the context of quantitative biology, it is commonly referred to
as the \emph{chemical master equation} (CME)
\begin{equation}\label{eq:cme}
    \frac{d\pi}{d t} ( x,t) =
    \sum_{j=1}^{n_R}\left(
        \alpha_j( x- v_j)\pi( x- v_j,t) - \alpha_j( x)\pi( x,t)
    \right)\,.
\end{equation}

\begin{example} Consider a birth-death process as a simple example. This model is used to describe a wide variety of phenomena and often constitutes a sub-module of larger models.
For example, it represents an M/M/1 queue with service rates being linearly dependent on the queue length.
Note that even for this simple model, the state-space is countably infinite.
% \MB{could remove model environment for space}
\begin{model}[Birth-Death Process]\label{model:bd}
The model consists of exponentially distributed arrivals and service times proportional to queue length. It can be expressed using two mass-action reactions:
$$ \varnothing \xrightarrow{\mu} S \qquad\text{and}\qquad S \xrightarrow{\gamma} \varnothing\,.$$
The initial condition $X_0=0$ holds with probability one.
\end{model}

For \autoref{model:bd} the change of probability mass in a single state $x>0$ is described by expanding
\eqref{eq:cme} and
$$\frac{d}{dt}\pi_t(x)=\gamma \pi_t(x-1) + \delta \pi_t(x+1) - (\gamma + \delta)\pi_t(x)\,.$$
\end{example}


\section{State-Space Truncation}\label{sec:fsp}
A direct solution of \eqref{eq:cme} is usually not possible.
If the state-space with non-negligible probability is suitably small, a state space
truncation could be performed.
That is, \eqref{eq:cme} is integrated on a possibly time-dependent subset
$\hat{\mathcal{S}}_t\subseteq\mathcal{S}$ \cite{henzinger2009sliding,munsky2006finite,spieler2014numerical}.
Transitions to states, that are not part of this subset are typically re-directed to a introduced sink-state.
This state captures the mass ``lost'' by the approximation and gives the error up to the numerical integration scheme.\graffito{Uniformization can give a lower bound on the error \cite{andreychenko2010fly}.}
\citet{munsky2006finite} coined the term of \acf{FSP} for such a method.

To analyze the stationary distribution (\autoref{sec:stationary_dist}) the redirection scheme needs to be altered \cite{kuntz2021stationary}:
Instead of a re-redirection into a sink-state, transitions are redirected in \emph{some fashion} back into the truncation set.

\section{Stochastic Simulations}\label{sec:ssa}
We can generate trajectories of this model using the \acf{SSA} (\autoref{alg:ssa})  \cite{gillespie1977exact}.
The simulation algorithm consists of repeatedly evaluating the race condition and jump times induced by~\eqref{eq:cme_generator} until some terminal criterion such as a maximum simulation time $T$ is reached (\autoref{line:loop}).
In particular, the algorithm iteratively chooses a reaction, with a probability that is
proportional to its rate given the current state $s$ (\autoref{line:sample_r}).
The jump time $t_j- t_{j+1}$ is determined by sampling from an exponential distribution with rate $\sum_i\alpha_i(s)$ (\autoref{line:sample_dt}).
\begin{algorithm}
    $\tau \leftarrow$ empty list, $s\leftarrow$ sample from $\pi_0$, $t\leftarrow 0$\;
	\While{$t<T$\label{line:loop}}{
		$k\leftarrow$ sample reaction $i$ with probability $\alpha_i(s)/\sum_i\alpha_i(s)$\label{line:sample_r}\;
	$\delta\sim \text{Exp}\left(\sum_i \alpha_i(s)\right)$\label{line:sample_dt}\;
        $s\leftarrow s + v_k$\;
	$t \leftarrow t + \delta$\;
	$\tau\leftarrow \text{append}(\tau, (s, t))$\;
    }
    \textbf{return} $\tau$\;
    \caption{\label{alg:ssa}Sample a trajectory}
\end{algorithm}


\section{Moment Dynamics}\label{sec:moments_bg}
Let $f$ be a polynomial function, $t\ge0$.
Using the \ac{CME} \eqref{eq:cme}, we can derive \acp{ODE}
describing the dynamics of $E(f(\vec{X}_t))$~\cite{engblom2006computing}.
Specifically,
\begin{equation}\label{eq:mom_ode}
    \frac{d}{dt}\E{f(\vec X_t)} = \sum_{j=1}^{n_R}\E{\left(f({\vec X_t +
    \vec{v_j}}) - f(\vec X_t)\right)\alpha_j(\vec X_t)}\,.
\end{equation}
This equation is used to analyse (raw) \emph{moments} of the process.
\graffito{\emph{Centered} or \emph{factorial} moments (such as the variance) are equivalent via the binomial transform.}
A raw moment is
$$\E{\vec X^{\vec m}}=\E{\prod_{i=1}^{n_S} X_i^{m_i}}\,,\quad \vec m\in {\mathbb{N}}^{n_S}$$
with respect to some probability measure.
The \emph{order} of a moment $E({\vec X}^{\vec m})$ is given by the sum of its exponents,
i.e.\ $\sum_i m_i$.
Note that the notion of  expected value can be generalized
to any measure $\mu$ on a Borel-measurable space
$(E, \mathcal{B}(E))$, where
 the $\vec{m}$-th raw moment is $\int_E {\vec x}^{\vec m}\,d\mu(\vec x)$.
Throughout we assume that moments of arbitrary order remain finite over time,
i.e.\ $E(\lvert \vec{X}^{\vec{m}}_t\rvert)<\infty$, $t\geq 0$.
In \citet{gupta2014scalable} the authors propose a framework to verify
this property for a given model.

\begin{example} Let us express the dynamics of the first two uncentered moments for \autoref{model:bd} using \eqref{eq:mom_ode}.
\begin{equation}\label{eq:bd:mom1}
	\begin{split}
	\frac{d}{dt}\E{X_t} =\; &\mu - \gamma \E{X_t}\\
	\frac{d}{dt}\E{X_t^2} =\; &\mu(2\E{X_t} + 1) - \gamma (2\E{X_t^2}-\E{X_t})%     −2𝑑𝑥2+𝑑𝑥+2𝑔𝑥+𝑔
	\end{split}
\end{equation}
Setting initial moments these equations give as an \ac{IVP}, we can solve (see \autoref{fig:momsandprobs}).
This, however, is more an exception than the norm:
Unless all ractions have linear or constant rate functions $\alpha_i(\cdot)$, $\forall i$, we would not end up with a closed system of \acp{ODE} as in \eqref{eq:bd:mom1}.
To illustrate, let us pretend the reaction ($S\xrightarrow{\gamma}\varnothing$) would become this non-linear reaction\graffito{The model is then the same as \autoref{model:dim}.}
$$
2S\xrightarrow{\gamma}\varnothing\,.
$$
Accordingly, due to mass-action \eqref{eq:stoch_mass_action}
$$
\alpha_2(x)=\gamma (x^2 - x)\,.
$$
Therefore the first moment's derivative becomes
$$
\frac{d}{dt}\E{X_t} =\mu - \gamma \left(\E{X_t^2} - \E{X_t}\right)\,.
$$
Note, that now the right-hand side of the derivative in the example depends on the value of the second moment $\E{X_t^2}$.
\end{example}
If we consider the general expression \eqref{eq:mom_ode} for the moment of order $k$ clearly a term of order $k+1$ occurs, that does (usually) not cancel out if a propensity function is at least
quadratic.
Therefore, researches commonly rely on ad-hoc approximations to truncate this infinite system of \acp{ODE} \cite{hespanha2008moment,schnoerr2015,schnoerr2014validity}.
Unfortunately such schemes have typically no guarantees to converge --~or even improve~-- with increasing truncation order \cite{schnoerr2014validity} or increasing system size.
The only scheme with a convergence guarantee in the system size limit is the \emph{mean-field} approximation \cite{bortolussi2013continuous}.
Therein zero-covariances are assumed, i.e.\ the system is truncated at the first oder equations using the approximation $\E{X_t^2}=\E{X_t}^2$.
\begin{figure}[htb]
	\centering
	\includegraphics[width=0.9\textwidth]{gfx/momsandprobs.pdf}
	\caption[Moments and probability distribution $\pi(t)$]{\label{fig:momsandprobs}The expected value $\pm$ a standard deviation along with a sampled trajectory (left) and the probability distribution over time (right) of \autoref{model:bd} with $\mu=10$ and $\gamma=0.1$.}
\end{figure}

\section{Stationary Distribution}\label{sec:stationary_dist}
Assuming
% irreducibility and 
ergodicity  
of the underlying chain, a stationary distribution $\pi_{\infty}$ is an invariant distribution, namely a fixed point of the Kolmogorov forward equation \eqref{eq:forward}.
Let $\pi_{\infty}$ be the vector description of a stationary distribution. It then  satisfies
\begin{equation}\label{eq:stationary}
0=\pi_{\infty}Q\quad\text{and}\quad 1=\sum_{x\in\mathcal{S}}\pi_{\infty}(x)
\end{equation}
as a fixed point of the Kolmogorov equation \eqref{eq:forward}.
Stationary distributions are connected to the \emph{long-run} behavior of an \ac{MPM}~\cite{dayar2011bounding}, as the system's distribution will converge to the (unique)
stationary distribution.
The connection of the stationary distribution to the long-run behavior becomes clear when considering the ergodic theorem. 
For some $A\subseteq\mathcal{S}$,
\begin{equation}\label{eq:ergodic}
    \lim_{T\to\infty}\frac{1}{T}\int_0^T 1_A(X_t)\,dt
    = \sum_{x\in A}\pi_{\infty}(x)\,.
\end{equation}
Thus, the mean occupation time for set $A$ over infinite trajectories is the stationary measure for $A$.
Eq.~\eqref{eq:ergodic} shows that we can assess long-run behavior using the stationary distribution and vice-versa.

\begin{example}
	Returning to the example of \autoref{model:bd} it is obvious that the state-space is irreducible.
Further, we can easily show, that the stationary distribution is Poissonian with rate $\mu/\gamma$:
$$ \pi_{\infty}(x)=\frac{{(\mu/\gamma)}^{x}\exp(-\mu/\gamma)}{x!}\,.$$
\end{example}


For simplicity, we assume throughout that the state-space is composed of a single communicating class.
Checking ergodicity given a countably infinite number of states is achieved by providing a suitable Foster-Lyapunov function \cite{meyn2012markov}.
Some automated techniques have been proposed for this task \cite{dayar2011bounding,gupta2014scalable,milias2014optimization}.



\subsection{Lyapunov Bounds}\label{sec:statagg:lyapunov}
It is well-known that for a \ac{CTMC} $X$, ergodicity can be proven by a Lyapunov function $g:\mathcal{S}\to\mathbb{R}_+$ \cite{meyn1993stability,dayar2011bounding}.\footnote{The positivity requirement can somewhat be relaxed. The function only needs to be bounded from below since it can be shifted to the positives. In practice this shift can be ignored since it cancels out in the drift \eqref{eq:drift}.}
Given the $g$, we define its \emph{drift} $d$ as its average infinitesimal change, which is obtained applying the generator $Q$ to $g$. 
\begin{equation}\label{eq:drift}
	d(x) = Qg(x) = \sum_{j=1}^{n_R} \alpha_j(x) (g(x+v_j) -  g(x))
\end{equation}
A Lyapunov function can be used to prove ergodicity of a \ac{CTMC}: If there is a finite subset $C\subset\mathcal{S}$ such that
\begin{align}
	&Qg(x)\leq -1,\; \forall x\in\mathcal{S}\setminus C\,,\\
	&Qg(x)< \infty,\; \forall x\in C\,, and\\
	&\lVert x\rVert\to\infty \Rightarrow g(x)\to\infty\,,\;\text{ where }\;\lVert x\rVert=\sum_i x_i\,,
\end{align}
then the chain is non-explosive and ergodic~\cite{milias2014optimization,tweedie_1975}.


Usually, such a function $g$ grows in all directions on the positive orthant, while its drift $d(x)$ decreases in all directions.
More formally, $g$ is characterized by having finite level sets $\{x\in\mathcal{S} \mid g(x) < l\}$ for all $l > 0$.
At the same time,
\begin{equation}\label{eq:lyapunov_set}
    \mathcal{C}_{\epsilon_{\ell}} = \{ x\in\mathcal{S} \mid
    \frac{\epsilon_{\ell}}{c}d(x) > \epsilon_{\ell} - 1\}
\end{equation}
should be finite, where $\infty> c\geq \sup_{x\in\mathcal{S}} d(x)$.
In this case, $\mathcal{C}_{\epsilon_{\ell}}$ contains at least $1-\epsilon_{\ell}$ of stationary probability mass for any $\epsilon_{\ell}\in(0,1)$ \cite[Thm.~8]{spieler2014numerical}.
Given that $\mathcal{C}_{\epsilon_{\ell}}$ is finite, the chain is ergodic and
\begin{equation}
    \sum_{x\in\mathcal{C}_{\epsilon_{\ell}}}\pi(x)> 1 - \epsilon_{\ell}
\end{equation}
bounding the stationary probability mass contained within $\mathcal{C}_{\epsilon_{\ell}}$.



\section{A Brief Taxonomy of Multimodality}\label{sec:multimodality}
Multimodality is an overloaded term in the context of reaction network models.
Specifically, it can be used to describe the following features.
\begin{description}
	\item[Operational Multimodality]
		This kind of multimodality characterizes the model behavior directly.
		Consider, for example, a gene
		expression model\graffito{\autoref{model:gexpr}
		on page~\pageref{model:gexpr} is an instance of this.}:
		The gene state is digital, meaning it is either active or inactive.
		Depending on this state a protein is either synthesized or not.
		Therefore the system has distinct \emph{operational modes}
		which dictate its dynamics.
		Non-biological examples can be found in the
		context of broadcasting systems,
		in which the dynamics change discretely due to messages shared between
		agents~\cite{bortolussi2020fluid}.

		Naturally, nearly all models change their dynamics,
		given a change in their state vector.
		In this aspect this distinction is not wholly strict.
		It is mainly intended to indicate distinctive changes in the dynamics.
		In some instances, these can be as obvious as the examples mentioned above.
		In other cases they may not be as obvious:
		Consider an epidemics die-out for example, which is a significant change
		in the operating mode, which is not due to a switch-type reaction.
  \item[Distributional Multimodality]
	  Here the multimodality refers to the stationary distribution $\pi_{\infty}$:
		It has multiple
		\emph{modes}, i.e.\ local maxima. Given an ergodic underlying \ac{CTMC}
		this entails, that the system spends most time in distinct regions of the
		state-space (cf.\ \eqref{eq:ergodic}).
		The \emph{switching} between those distinct region is of interest
		for both, analysis and control, of such models.
\end{description}
While distributional multimodality implies operational multimodality, the reverse
does not hold.

Literature:
\begin{itemize}
	\item \cite{siegal2011emergence}
\end{itemize}
