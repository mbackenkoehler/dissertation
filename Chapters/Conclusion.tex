\chapter{Conclusion}
While \acfp{MPM} are a versatile modeling framework, their analysis --~especially wrt.\ their stochasticity~-- poses a significant challenge.
% Talk more about the stochasticity and give examples of model queries involving stochasticity.
This thesis has proposed several techniques to tackle some parts of this challenge.
All of these techniques use the uniform structure of the \acp{CTMC} underlying an \ac{MPM}.

This structure enables us to derive moment equations that yield constraints that have shown to be useful in two contexts.
In the context of mean first-passage time bounds, they formed linear constraints on the moments of the process and the exit location measure.
Together with semi-definite constraints, this yields a hierarchy of convex optimization problems.
This hierarchy yields convergent bounds on the reaching probability and the mean first-passage time in a wide class of problems.
The other application of these moments constraints has been demonstrated in the context of Monte Carlo estimation:
When used as \acfp{CV} such constraints yield an alternative unbiased estimator with lower variance.
Using heuristics and sequential Monte Carlo methods, we demonstrated methods to construct efficient constraint.

The aggregation approach takes advantage of the fact that often propensity functions result in a smooth ``landscape of transition rates'' across the state-space.
This motivates an aggregation scheme that approximates a uniform distribution inside macro-states.
Deriving closed forms for the transition rates between those states significantly reduces the computational load compared to the original model.
We have demonstrated the usefulness of this aggregation scheme in the domains of stationary distributions, bridging distributions, and the use in rare event sampling.


%\section{Contribution}
%\emph{Main methodology}: The uniform structure of population models enables analysis using aggregate information (in the state domain or by using moment statistics)
%\begin{itemize}
  %\item Proposed novel methodologies
  %\item spanning from rigorous to more heuristic
  %\item hate on ad-hoc heuristics a little (i.e.\ moment closures)
  %\item all methods have an approximating relationship with the actual model (convergence to the actual dynamics) -- illustrate!
%\end{itemize}
\section{Future Work}
All ideas presented in this thesis provide starting points for future work.

\paragraph{Mean First-Passage Times via Semi-Definite Programming}
The \ac{SDP} approach for \acp{MFPT} presented in \autoref{ch:MFPT} improved in terms of scalability.
Here, scalability mainly refers to the problem of large populations (or time horizons).
Such large values increase the moments which tend to grow exponentially with their order.
The resulting stiffness can be problematic for off-the-shelf \ac{SDP} solvers.
Better performance could be achieved by a suitable re-scaling of the model or stronger cooperation with domain experts in mathematical optimization to pinpoint problems more precisely.
Another interesting direction is the study of Hausdorff constraints sketched in \autoref{sec:hausdorff}.
Since these are linear moment constraints, they can easily be incorporated into the \ac{SDP} formulation.

\paragraph{Control Variates}
Control variates for Monte Carlo (\autoref{ch:cvinsrns} estimation offer a tremendous design space, both algorithmically and in terms of the constraints themselves.
Depending on the quantity of interest, non-polynomial test functions might provide better correlations.
The control variate optimization, based on sequential Monte Carlo, could perhaps be replaced by a search using approximations such as moment closures.
A challenge in designing \acp{CV} and their algorithmic optimization is always elegance.
Keeping the algorithm flexible, while keeping the number of parameters low is difficult, but crucial.

\paragraph{Aggregation}
Similarly to the \aclp{CV}, the aggregation scheme offers quite a few possibilities for further experimentation.
For example, a dynamic aggregation-disaggregation scheme could be used for forward analysis similar to dynamic truncations \parencite{andreychenko2011parameter}.
Another possible modification would be to define states more flexible than hyper cubes.
Other shapes might be better suited for this kind of approximation.

%\paragraph{Technical}
%\begin{itemize}
    %\item aggregation: Schemes more flexible than hyper-cubes (rectangles instead of cubes, other shapes altogether)
    %\item More throgough investigation / further development of sketched ideas (Lyapunov synthesis, Rare event sampling)
%\end{itemize}
\paragraph{General}
The main challenge in stochastic reaction networks today is the connection of methods to practitioners and their problems.
A large area body of research is devoted to methods precisely analyzing \acp{SRN}.
It is a danger that the practical value of proposed methods is a secondary concern.
For these methods to be useful, more dialog is needed with domain experts to understand the challenges.
Only then can the new approaches --~such as the ones presented in this thesis~-- develop practical uses.
%\begin{itemize}
%    \item Method and model development should be driven more by practical problems (what do practicioners actually need?)
%  \item Prove methods on some domain; drive research using new possibilities
%  \item Re-assess
%\end{itemize}
%\paragraph{Last Message}
%\begin{itemize}
  %\item Lots of things are possible --- go ahead and apply them!
%\end{itemize}
